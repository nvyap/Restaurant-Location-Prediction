{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 - Location Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore warnings \n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Phoenix Business Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>business_id</th>\n",
       "      <th>Mexican</th>\n",
       "      <th>American (Traditional)</th>\n",
       "      <th>Pizza</th>\n",
       "      <th>American (New)</th>\n",
       "      <th>Burgers</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>Salad</th>\n",
       "      <th>...</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_age</th>\n",
       "      <th>under_18</th>\n",
       "      <th>above_18</th>\n",
       "      <th>walkscore</th>\n",
       "      <th>ffall</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>ffall_category</th>\n",
       "      <th>CuisineCombined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85007</td>\n",
       "      <td>_c3ixq9jYKxhLUB0czi0ug</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>27557</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3652</td>\n",
       "      <td>8906</td>\n",
       "      <td>60.0</td>\n",
       "      <td>987</td>\n",
       "      <td>4.0</td>\n",
       "      <td>277</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   zipcode             business_id  Mexican  American (Traditional)  Pizza  \\\n",
       "0    85007  _c3ixq9jYKxhLUB0czi0ug        0                       0      0   \n",
       "\n",
       "   American (New)  Burgers  Italian  Chinese  Salad       ...         \\\n",
       "0               0        1        0        0      0       ...          \n",
       "\n",
       "   median_income  median_age  under_18  above_18  walkscore  ffall  stars  \\\n",
       "0          27557        35.0      3652      8906       60.0    987    4.0   \n",
       "\n",
       "   review_count  ffall_category  CuisineCombined  \n",
       "0           277               4               14  \n",
       "\n",
       "[1 rows x 70 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('../../../data/phoenix_business_ws_rw_ffall_merged2.csv', skipinitialspace=True)\n",
    "\n",
    "raw_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the available attibutes in the given dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dframe = raw_data[(raw_data['ffall']<=1500) & (raw_data['ffall']>=3)]\n",
    "dframe = raw_data\n",
    "dframe['totalStars'] = dframe['review_count'] * dframe['stars']\n",
    "dframe['adjwhp'] = dframe['white_pop'] * dframe['stars']\n",
    "dframe['adjpafp'] = dframe['afam_pop'] * dframe['stars']\n",
    "dframe['adjindp'] = dframe['amindian_pop'] * dframe['stars']\n",
    "dframe['adjasp'] = dframe['asian_pop'] * dframe['stars']\n",
    "dframe['adjhwp'] = dframe['hawaiian_pop'] * dframe['stars']\n",
    "dframe['adjorp'] = dframe['other_race'] * dframe['stars']\n",
    "\n",
    "train, test = train_test_split(dframe, test_size=0.05)\n",
    "#dframe[['white_pop', 'adjwhp', 'stars','zipcode']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_means_df = dframe.groupby(['zipcode']).agg([np.mean])\n",
    "zip_avg_ffall_revC_list = []\n",
    "rowitem = []\n",
    "\n",
    "for ind, row in zip_means_df.iterrows():\n",
    "    zip_avg_ffall_revC_list.append([ind, row.iloc[65], row.iloc[63], row[66]])\n",
    "    \n",
    "zip_avg_ffall_revC_df = pd.DataFrame(zip_avg_ffall_revC_list, columns=['zipcode','avgrc','avgffall', 'avgffc'])\n",
    "zip_avg_ffall_revC_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Finer split in Asian Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_data = pd.read_csv('../../../data/arizon.csv', skipinitialspace=True)\n",
    "\n",
    "selected_pop = pop_data[['zipcode', 'PCT0050002', 'PCT0050003', 'PCT0050004', 'PCT0050005', 'PCT0050006',\n",
    "       'PCT0050007', 'PCT0050008', 'PCT0050009', 'PCT0050010', 'PCT0050011',\n",
    "       'PCT0050012', 'PCT0050013', 'PCT0050014', 'PCT0050015', 'PCT0050016',\n",
    "       'PCT0050017', 'PCT0050018', 'PCT0050019', 'PCT0050020', 'PCT0050021',\n",
    "       'PCT0050022']]\n",
    "\n",
    "joined_data = dframe.merge(selected_pop, left_on=\"zipcode\", right_on=\"zipcode\", how=\"inner\", suffixes = (\"_a\",\"_b\"))\n",
    "\n",
    "final_data = joined_data.merge(zip_avg_ffall_revC_df, left_on=\"zipcode\", right_on=\"zipcode\", how=\"inner\", \n",
    "                            suffixes = (\"_a\",\"_b\"))\n",
    "final_data['stars_avgffc'] = final_data['stars'] * final_data['avgffall']\n",
    "final_data['stars_avgrc'] = final_data['stars'] * final_data['avgffall'] * final_data['total_pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select training and testing data\n",
    "train, test = train_test_split(final_data, test_size=0.05)\n",
    "\n",
    "# Select columns\n",
    "X_train = train.drop(columns=['zipcode','business_id', 'CuisineCombined','total_pop',\n",
    "                              'male','female','under_18','above_18','occupied_housing_units', 'review_count', \n",
    "                              'stars', 'ffall', 'zipcode.1', 'median_age', 'zipcode.1', \n",
    "                              'asian_pop', 'avgrc', 'ffall_category', 'white_pop', 'afam_pop', 'amindian_pop', \n",
    "                              'hawaiian_pop', 'other_race', 'avgffall', 'totalStars'])\n",
    "#dframe[['white_pop', 'afam_pop', 'amindian_pop', 'hawaiian_pop', 'other_race']]\n",
    "y_train = train['ffall']\n",
    "\n",
    "X_train.head()\n",
    "y_train.head()\n",
    "\n",
    "X_test = test.drop(columns=['zipcode','business_id','CuisineCombined','total_pop','male','female',\n",
    "                            'under_18','above_18','occupied_housing_units', 'review_count', 'stars', 'ffall', \n",
    "                            'zipcode.1','median_age', 'zipcode.1', 'asian_pop', 'avgrc', 'ffall_category', \n",
    "                            'white_pop', 'afam_pop', 'amindian_pop', 'hawaiian_pop', 'other_race', 'avgffall',\n",
    "                           'totalStars'])\n",
    "y_test = test['ffall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_sc = scaler.transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Basic Model - Linear Regression\n",
    "#### 2.1.1. Build and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.703939\n",
      "0.2481977259567133\n",
      "0.2419185169545659\n"
     ]
    }
   ],
   "source": [
    "#Regression\n",
    "lmod = LinearRegression()\n",
    "lmod.fit(X_train_sc, np.log(y_train))\n",
    "\n",
    "preds = lmod.predict(X_test_sc)\n",
    "rmse = np.sqrt(mean_squared_error(np.log(y_test), preds))\n",
    "\n",
    "#Model details\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "print(r2_score(np.log(y_train), lmod.predict(X_train_sc)))\n",
    "print(r2_score(np.log(y_test), preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.10906642 -2.73661749 -3.00118509 -2.90207917 -2.92955439 -2.89052942\n",
      " -3.00066619 -2.5268311  -2.51511659 -2.41576436]\n",
      "Avg Mean Squared Error: -2.80 (+/- 0.46)\n"
     ]
    }
   ],
   "source": [
    "clf = LinearRegression()\n",
    "scores = cross_val_score(clf, X_train, np.log(y_train), cv=10, scoring='mean_squared_error')\n",
    "\n",
    "print(scores)\n",
    "print(\"Avg Mean Squared Error: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Random Forest Regressor\n",
    "#### 2.2.1. Tune and select model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier - Grid Search - Best params:  {'max_depth': 5, 'n_estimators': 50}\n",
      "Random forest classifier - Grid Search - Best Score:  -2.713768954864803\n"
     ]
    }
   ],
   "source": [
    "# Search for a good model\n",
    "\n",
    "params = [{'n_estimators': [10, 20, 50], 'max_depth': [5, 10, 15] }]\n",
    "clf = GridSearchCV(RandomForestRegressor(), params, cv=10, scoring='mean_squared_error')\n",
    "clf.fit(X_train, np.log(y_train))\n",
    "print(\"Random forest classifier - Grid Search - Best params: \", clf.best_params_)\n",
    "print(\"Random forest classifier - Grid Search - Best Score: \", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.92289373 -2.58004703 -2.88027509 -3.04114715 -2.72162884 -2.70302585\n",
      " -2.89689817 -2.60082256 -2.50440024 -2.33269273]\n",
      "Avg Mean Squared Error: -2.72 (+/- 0.42)\n"
     ]
    }
   ],
   "source": [
    "# Running on selected model {'max_depth': 10, 'n_estimators': 50}\n",
    "# Selected model parameters \n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 50, max_depth = 5)\n",
    "scores = cross_val_score(rf, X_train, np.log(y_train), cv=10, scoring='mean_squared_error')\n",
    "\n",
    "print(scores)\n",
    "print(\"Avg Mean Squared Error: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier - Grid Search - Best params:  {'alpha': 10, 'colsample_bytree': 0.6, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'objective': 'reg:linear'}\n",
      "Random forest classifier - Grid Search - Best Score:  -2.6673804464462183\n"
     ]
    }
   ],
   "source": [
    "# Tune and select XGB Regressor\n",
    "params = [{'learning_rate': [0.01, 0.1, 0.5], 'n_estimators': [10, 25, 50], 'max_depth': [5, 10, 15], \n",
    "           'colsample_bytree': [0.3, 0.6, 0.9], 'objective': ['reg:linear'], 'alpha': [10]}]\n",
    "\n",
    "clf = GridSearchCV(xgb.XGBRegressor(), params, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "clf.fit(X_train, np.log(y_train))\n",
    "print(\"Random forest classifier - Grid Search - Best params: \", clf.best_params_)\n",
    "print(\"Random forest classifier - Grid Search - Best Score: \", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.01803029 -2.47958063 -2.81973953 -3.00156972 -2.68695634 -2.74771821\n",
      " -2.80693479 -2.49985417 -2.34728219 -2.26496243]\n",
      "Avg Mean Squared Error: -2.67 (+/- 0.49)\n"
     ]
    }
   ],
   "source": [
    "# Running on selected model \n",
    "# Selected model parameters: {'alpha': 10, 'colsample_bytree': 0.9, 'learning_rate': 0.1, \n",
    "# 'max_depth': 5, 'n_estimators': 100, 'objective': 'reg:linear'}\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.6, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 50)\n",
    "\n",
    "scores = cross_val_score(xg_reg, X_train, np.log(y_train), cv=10, scoring='mean_squared_error')\n",
    "\n",
    "print(scores)\n",
    "print(\"Avg Mean Squared Error: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Selecting a model and reporting RMSE on Test set\n",
    "\n",
    "All models do not have a major different in the RMSE. Hence, choosing Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Select Final Set of Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = final_data\n",
    "\n",
    "col_list = ['PCT0050002', 'PCT0050003', 'PCT0050004', 'PCT0050005', 'PCT0050006',\n",
    "       'PCT0050007', 'PCT0050008', 'PCT0050009', 'PCT0050010', 'PCT0050011',\n",
    "       'PCT0050012', 'PCT0050013', 'PCT0050014', 'PCT0050015', 'PCT0050016',\n",
    "       'PCT0050017', 'PCT0050018', 'PCT0050019', 'PCT0050020', 'PCT0050021',\n",
    "       'PCT0050022']\n",
    "\n",
    "#for item in col_list:\n",
    "#    final_test[item] *= final_test['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select training and testing data\n",
    "train, test = train_test_split(final_test, test_size=0.05)\n",
    "\n",
    "# Select columns\n",
    "X_train = train.drop(columns=['zipcode','business_id', 'CuisineCombined','total_pop',\n",
    "                              'male','female','under_18','above_18','occupied_housing_units', 'review_count', \n",
    "                              'ffall', 'zipcode.1', 'median_age', 'zipcode.1', \n",
    "                              'asian_pop', 'avgrc', 'ffall_category', 'white_pop', 'afam_pop', 'amindian_pop', \n",
    "                              'hawaiian_pop', 'other_race', 'median_income', 'totalStars', 'stars_avgffc'])\n",
    "#dframe[['white_pop', 'afam_pop', 'amindian_pop', 'hawaiian_pop', 'other_race']]\n",
    "y_train = train['ffall']\n",
    "\n",
    "X_train.head()\n",
    "y_train.head()\n",
    "\n",
    "X_test = test.drop(columns=['zipcode','business_id', 'CuisineCombined','total_pop',\n",
    "                              'male','female','under_18','above_18','occupied_housing_units', 'review_count', \n",
    "                              'ffall', 'zipcode.1', 'median_age', 'zipcode.1', \n",
    "                              'asian_pop', 'avgrc', 'ffall_category', 'white_pop', 'afam_pop', 'amindian_pop', \n",
    "                              'hawaiian_pop', 'other_race', 'median_income', 'totalStars', 'stars_avgffc'])\n",
    "y_test = test['ffall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.1327331  -2.40508174 -2.69523127 -3.04701763 -2.66498125 -2.38010845\n",
      " -2.92585143 -2.31445344 -3.02341225 -2.8759091 ]\n",
      "Avg Mean Squared Error: -2.65 (+/- 0.61)\n",
      "R-Square on Training set 0.4198573599798303\n",
      "R-Square on Testing set 0.2834138031141984\n"
     ]
    }
   ],
   "source": [
    "# Running on selected model \n",
    "# Selected model parameters: {'alpha': 10, 'colsample_bytree': 0.9, 'learning_rate': 0.1, \n",
    "# 'max_depth': 5, 'n_estimators': 100, 'objective': 'reg:linear'}\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.6, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 50)\n",
    "\n",
    "scores = cross_val_score(xg_reg, X_train, np.log(y_train), cv=10, scoring='mean_squared_error')\n",
    "print(scores)\n",
    "print(\"Avg Mean Squared Error: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "xg_reg.fit(X_train, np.log(y_train))\n",
    "print(\"R-Square on Training set\", r2_score(np.log(y_train), xg_reg.predict(X_train)))\n",
    "print(\"R-Square on Testing set\", r2_score(np.log(y_test), xg_reg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Selected Model is listed in 3.1.\n",
    "\n",
    "#### 3.2.1. Model: XGBoostRegressor\n",
    "#### 3.2.2. R-Square : 42.47%\n",
    "#### 3.2.3. Mean RMSE: 2.67 (+/- 0.49)\n",
    "\n",
    "#### Selected Cols:\n",
    "       'Mexican', 'American (Traditional)', 'Pizza', 'American (New)',\n",
    "       'Burgers', 'Italian', 'Chinese', 'Salad', 'Sports Bars', 'Seafood',\n",
    "       'Japanese', 'Barbeque', 'Mediterranean', 'Sushi Bars', 'Asian Fusion',\n",
    "       'Steakhouses', 'Greek', 'Tex-Mex', 'Thai', 'Vietnamese', 'Indian',\n",
    "       'Middle Eastern', 'Southern', 'Latin American', 'Hawaiian', 'Korean',\n",
    "       'French', 'Caribbean', 'Pakistani', 'Ramen', 'New Mexican Cuisine',\n",
    "       'Modern European', 'Spanish', 'African', 'Cantonese', 'Persian/Iranian',\n",
    "       'Filipino', 'Cuban', 'Mongolian', 'Lebanese', 'Polish', 'Taiwanese',\n",
    "       'German', 'Turkish', 'Ethiopian', 'Brazilian', 'Afghan', 'walkscore',\n",
    "       'stars', 'adjwhp', 'adjpafp', 'adjindp', 'adjasp', 'adjhwp', 'adjorp',\n",
    "       'PCT0050002', 'PCT0050003', 'PCT0050004', 'PCT0050005', 'PCT0050006',\n",
    "       'PCT0050007', 'PCT0050008', 'PCT0050009', 'PCT0050010', 'PCT0050011',\n",
    "       'PCT0050012', 'PCT0050013', 'PCT0050014', 'PCT0050015', 'PCT0050016',\n",
    "       'PCT0050017', 'PCT0050018', 'PCT0050019', 'PCT0050020', 'PCT0050021',\n",
    "       'PCT0050022', 'avgffall', 'avgffc', 'stars_avgrc'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
